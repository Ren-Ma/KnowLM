[2023-07-21 18:34:15,449] [WARNING] [runner.py:191:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-07-21 18:34:15,522] [INFO] [runner.py:541:main] cmd = /root/anaconda3/envs/unichat/bin/python3.10 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None train.py --model_name_or_path /data/caihua/huggingfaceModels/llama/llama-13B --model_max_length 1024 --data_path /data/renma/unigpt//law_data/wenshu5w/民事案件data --output_dir /data/renma/unigpt//KnowLM/pretrain/output --num_train_epochs 1 --per_device_train_batch_size 16 --per_device_eval_batch_size 1 --evaluation_strategy no --save_strategy steps --save_steps 100 --save_total_limit 1 --learning_rate 1.5e-5 --warmup_steps 300 --logging_steps 1 --report_to tensorboard --gradient_checkpointing True --deepspeed /data/renma/unigpt//KnowLM/pretrain/configs/config.json --fp16 True --log_on_each_node False --lr_scheduler_type cosine --adam_beta1 0.9 --adam_beta2 0.95 --weight_decay 0.1
[2023-07-21 18:34:17,697] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2023-07-21 18:34:17,697] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=8, node_rank=0
[2023-07-21 18:34:17,697] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2023-07-21 18:34:17,697] [INFO] [launch.py:247:main] dist_world_size=8
[2023-07-21 18:34:17,697] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2023-07-21 18:34:22,062] [INFO] [comm.py:622:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:08<00:16,  8.08s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:10<00:21, 10.72s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:12<00:24, 12.02s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:12<00:24, 12.05s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:11<00:23, 11.71s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:11<00:23, 11.71s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:12<00:24, 12.28s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:10<00:21, 10.83s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:17<00:08,  8.68s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:17<00:08,  8.59s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:23<00:11, 11.57s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:22<00:11, 11.41s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:22<00:11, 11.43s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:23<00:11, 11.67s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:23<00:11, 11.69s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:23<00:00,  7.78s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:23<00:00,  7.96s/it]
数据的分布为：[96273]
False
Loading checkpoint shards:  67%|██████▋   | 2/3 [00:22<00:11, 11.06s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:25<00:00,  7.98s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:25<00:00,  8.35s/it]
数据的分布为：[96273]
False
Loading checkpoint shards: 100%|██████████| 3/3 [00:29<00:00,  9.41s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:29<00:00,  9.98s/it]
数据的分布为：[96273]
False
Loading checkpoint shards: 100%|██████████| 3/3 [00:30<00:00,  9.72s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:30<00:00, 10.26s/it]
数据的分布为：[96273]
False
Loading checkpoint shards: 100%|██████████| 3/3 [00:30<00:00,  9.65s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:30<00:00, 10.16s/it]
数据的分布为：[96273]
False
Loading checkpoint shards: 100%|██████████| 3/3 [00:31<00:00, 10.24s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:31<00:00, 10.66s/it]
数据的分布为：[96273]
False
Loading checkpoint shards: 100%|██████████| 3/3 [00:30<00:00,  9.89s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:30<00:00, 10.18s/it]
数据的分布为：[96273]
False
Loading checkpoint shards: 100%|██████████| 3/3 [00:33<00:00, 11.04s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:33<00:00, 11.28s/it]
数据的分布为：[96273]
False
Installed CUDA version 11.4 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.4 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.4 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...


Installed CUDA version 11.4 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
确认ninja！
Installed CUDA version 11.4 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Installed CUDA version 11.4 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Installed CUDA version 11.4 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Installed CUDA version 11.4 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /data/.cache/torch_extensions/py310_cu117/fused_adam/build.ninja...
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 0.10713028907775879 seconds
Time to load fused_adam op: 0.10174131393432617 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 0.10150599479675293 seconds
Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
确认ninja！
Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Emitting ninja build file /data/.cache/torch_extensions/py310_cu117/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Time to load fused_adam op: 0.10144805908203125 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 0.10223150253295898 seconds
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.06529664993286133 seconds
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 0.20268821716308594 seconds
Time to load fused_adam op: 0.20272064208984375 seconds
Time to load fused_adam op: 0.20178842544555664 seconds
Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...

确认ninja！
Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Emitting ninja build file /data/.cache/torch_extensions/py310_cu117/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.06286764144897461 seconds
Loading extension module utils...
Time to load utils op: 0.1014719009399414 seconds
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.10158634185791016 seconds
Time to load utils op: 0.10171318054199219 seconds
Time to load utils op: 0.10127949714660645 seconds
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.2018418312072754 seconds
Time to load utils op: 0.20131921768188477 seconds
Rank: 2 partition count [8] and sizes[(1626983040, False)] 
Rank: 5 partition count [8] and sizes[(1626983040, False)] 
Rank: 4 partition count [8] and sizes[(1626983040, False)] 
Rank: 0 partition count [8] and sizes[(1626983040, False)] 
Rank: 1 partition count [8] and sizes[(1626983040, False)] 
Rank: 3 partition count [8] and sizes[(1626983040, False)] 
Rank: 7 partition count [8] and sizes[(1626983040, False)] 
Rank: 6 partition count [8] and sizes[(1626983040, False)] 
Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.000736236572265625 seconds
Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0011086463928222656 seconds
Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0006992816925048828 seconds
Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0007200241088867188 seconds
Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0008449554443359375 seconds
Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0007157325744628906 seconds
Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0009865760803222656 seconds
Using /data/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.00041937828063964844 seconds
  0%|          | 0/753 [00:00<?, ?it/s]  0%|          | 1/753 [00:18<3:56:51, 18.90s/it]                                                 {'loss': 1.6559, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 1/753 [00:18<3:56:51, 18.90s/it]  0%|          | 2/753 [00:37<3:55:28, 18.81s/it]                                                 {'loss': 1.6825, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 2/753 [00:37<3:55:28, 18.81s/it]  0%|          | 3/753 [00:57<4:01:17, 19.30s/it]                                                 {'loss': 1.6549, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 3/753 [00:57<4:01:17, 19.30s/it]  1%|          | 4/753 [01:16<3:59:54, 19.22s/it]                                                 {'loss': 1.6294, 'learning_rate': 0.0, 'epoch': 0.01}
  1%|          | 4/753 [01:16<3:59:54, 19.22s/it]  1%|          | 5/753 [01:35<3:58:23, 19.12s/it]                                                 {'loss': 1.6821, 'learning_rate': 0.0, 'epoch': 0.01}
  1%|          | 5/753 [01:35<3:58:23, 19.12s/it]  1%|          | 6/753 [01:54<3:57:35, 19.08s/it]                                                 {'loss': 1.6521, 'learning_rate': 0.0, 'epoch': 0.01}
  1%|          | 6/753 [01:54<3:57:35, 19.08s/it]  1%|          | 7/753 [02:14<4:00:24, 19.34s/it]                                                 {'loss': 1.666, 'learning_rate': 0.0, 'epoch': 0.01}
  1%|          | 7/753 [02:14<4:00:24, 19.34s/it]  1%|          | 8/753 [02:33<3:58:57, 19.24s/it]                                                 {'loss': 1.6237, 'learning_rate': 0.0, 'epoch': 0.01}
  1%|          | 8/753 [02:33<3:58:57, 19.24s/it]  1%|          | 9/753 [02:52<3:58:44, 19.25s/it]                                                 {'loss': 1.6426, 'learning_rate': 0.0, 'epoch': 0.01}
  1%|          | 9/753 [02:52<3:58:44, 19.25s/it]  1%|▏         | 10/753 [03:11<3:56:14, 19.08s/it]                                                  {'loss': 1.6631, 'learning_rate': 0.0, 'epoch': 0.01}
  1%|▏         | 10/753 [03:11<3:56:14, 19.08s/it]  1%|▏         | 11/753 [03:30<3:55:38, 19.06s/it]                                                  {'loss': 1.6644, 'learning_rate': 0.0, 'epoch': 0.01}
  1%|▏         | 11/753 [03:30<3:55:38, 19.06s/it]  2%|▏         | 12/753 [03:49<3:54:06, 18.96s/it]                                                  {'loss': 1.6339, 'learning_rate': 0.0, 'epoch': 0.02}
  2%|▏         | 12/753 [03:49<3:54:06, 18.96s/it]  2%|▏         | 13/753 [04:08<3:53:55, 18.97s/it]                                                  {'loss': 1.6791, 'learning_rate': 0.0, 'epoch': 0.02}
  2%|▏         | 13/753 [04:08<3:53:55, 18.97s/it]  2%|▏         | 14/753 [04:27<3:54:04, 19.01s/it]                                                  {'loss': 1.6418, 'learning_rate': 0.0, 'epoch': 0.02}
  2%|▏         | 14/753 [04:27<3:54:04, 19.01s/it]  2%|▏         | 15/753 [04:46<3:54:40, 19.08s/it]                                                  {'loss': 1.6772, 'learning_rate': 0.0, 'epoch': 0.02}
  2%|▏         | 15/753 [04:46<3:54:40, 19.08s/it]  2%|▏         | 16/753 [05:06<3:56:48, 19.28s/it]                                                  {'loss': 1.6312, 'learning_rate': 0.0, 'epoch': 0.02}
  2%|▏         | 16/753 [05:06<3:56:48, 19.28s/it]  2%|▏         | 17/753 [05:25<3:55:28, 19.20s/it]                                                  {'loss': 1.5956, 'learning_rate': 0.0, 'epoch': 0.02}
  2%|▏         | 17/753 [05:25<3:55:28, 19.20s/it]  2%|▏         | 18/753 [05:44<3:55:04, 19.19s/it]                                                  {'loss': 1.6519, 'learning_rate': 0.0, 'epoch': 0.02}
  2%|▏         | 18/753 [05:44<3:55:04, 19.19s/it]  3%|▎         | 19/753 [06:06<4:04:23, 19.98s/it]                                                  {'loss': 1.6379, 'learning_rate': 5.0000000000000004e-08, 'epoch': 0.03}
  3%|▎         | 19/753 [06:06<4:04:23, 19.98s/it]  3%|▎         | 20/753 [06:28<4:11:25, 20.58s/it]                                                  {'loss': 1.614, 'learning_rate': 1.0000000000000001e-07, 'epoch': 0.03}
  3%|▎         | 20/753 [06:28<4:11:25, 20.58s/it]  3%|▎         | 21/753 [06:50<4:17:38, 21.12s/it]                                                  {'loss': 1.671, 'learning_rate': 1.5000000000000002e-07, 'epoch': 0.03}
  3%|▎         | 21/753 [06:50<4:17:38, 21.12s/it]  3%|▎         | 22/753 [07:12<4:20:16, 21.36s/it]                                                  {'loss': 1.6786, 'learning_rate': 2.0000000000000002e-07, 'epoch': 0.03}
  3%|▎         | 22/753 [07:12<4:20:16, 21.36s/it]  3%|▎         | 23/753 [07:35<4:26:05, 21.87s/it]                                                  {'loss': 1.6674, 'learning_rate': 2.5e-07, 'epoch': 0.03}
  3%|▎         | 23/753 [07:35<4:26:05, 21.87s/it]  3%|▎         | 24/753 [07:57<4:24:21, 21.76s/it]                                                  {'loss': 1.6482, 'learning_rate': 3.0000000000000004e-07, 'epoch': 0.03}
  3%|▎         | 24/753 [07:57<4:24:21, 21.76s/it]  3%|▎         | 25/753 [08:18<4:22:46, 21.66s/it]                                                  {'loss': 1.642, 'learning_rate': 3.5000000000000004e-07, 'epoch': 0.03}
  3%|▎         | 25/753 [08:18<4:22:46, 21.66s/it]  3%|▎         | 26/753 [08:41<4:25:59, 21.95s/it]                                                  {'loss': 1.6538, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.03}
  3%|▎         | 26/753 [08:41<4:25:59, 21.95s/it]  4%|▎         | 27/753 [09:03<4:28:32, 22.19s/it]                                                  {'loss': 1.6329, 'learning_rate': 4.5e-07, 'epoch': 0.04}
  4%|▎         | 27/753 [09:03<4:28:32, 22.19s/it]  4%|▎         | 28/753 [09:26<4:28:10, 22.19s/it]                                                  {'loss': 1.6313, 'learning_rate': 5e-07, 'epoch': 0.04}
  4%|▎         | 28/753 [09:26<4:28:10, 22.19s/it]  4%|▍         | 29/753 [09:47<4:23:36, 21.85s/it]                                                  {'loss': 1.6283, 'learning_rate': 5.5e-07, 'epoch': 0.04}
  4%|▍         | 29/753 [09:47<4:23:36, 21.85s/it]  4%|▍         | 30/753 [10:08<4:20:40, 21.63s/it]                                                  {'loss': 1.574, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.04}
  4%|▍         | 30/753 [10:08<4:20:40, 21.63s/it]  4%|▍         | 31/753 [10:30<4:23:48, 21.92s/it]                                                  {'loss': 1.5664, 'learning_rate': 6.5e-07, 'epoch': 0.04}
  4%|▍         | 31/753 [10:30<4:23:48, 21.92s/it]  4%|▍         | 32/753 [10:53<4:27:01, 22.22s/it]                                                  {'loss': 1.5708, 'learning_rate': 7.000000000000001e-07, 'epoch': 0.04}
  4%|▍         | 32/753 [10:53<4:27:01, 22.22s/it]  4%|▍         | 33/753 [11:14<4:20:45, 21.73s/it]                                                  {'loss': 1.561, 'learning_rate': 7.5e-07, 'epoch': 0.04}
  4%|▍         | 33/753 [11:14<4:20:45, 21.73s/it]  5%|▍         | 34/753 [11:35<4:17:08, 21.46s/it]                                                  {'loss': 1.5291, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.05}
  5%|▍         | 34/753 [11:35<4:17:08, 21.46s/it]  5%|▍         | 35/753 [11:56<4:17:06, 21.49s/it]                                                  {'loss': 1.4907, 'learning_rate': 8.5e-07, 'epoch': 0.05}
  5%|▍         | 35/753 [11:56<4:17:06, 21.49s/it]  5%|▍         | 36/753 [12:17<4:15:10, 21.35s/it]                                                  {'loss': 1.5033, 'learning_rate': 9e-07, 'epoch': 0.05}
  5%|▍         | 36/753 [12:17<4:15:10, 21.35s/it]  5%|▍         | 37/753 [12:39<4:16:46, 21.52s/it]                                                  {'loss': 1.4694, 'learning_rate': 9.500000000000001e-07, 'epoch': 0.05}
  5%|▍         | 37/753 [12:39<4:16:46, 21.52s/it]  5%|▌         | 38/753 [13:02<4:22:26, 22.02s/it]                                                  {'loss': 1.4165, 'learning_rate': 1e-06, 'epoch': 0.05}
  5%|▌         | 38/753 [13:02<4:22:26, 22.02s/it]  5%|▌         | 39/753 [13:24<4:21:42, 21.99s/it]                                                  {'loss': 1.3859, 'learning_rate': 1.0500000000000001e-06, 'epoch': 0.05}
  5%|▌         | 39/753 [13:24<4:21:42, 21.99s/it]  5%|▌         | 40/753 [13:45<4:17:35, 21.68s/it]                                                  {'loss': 1.3542, 'learning_rate': 1.1e-06, 'epoch': 0.05}
  5%|▌         | 40/753 [13:45<4:17:35, 21.68s/it]  5%|▌         | 41/753 [14:07<4:18:09, 21.76s/it]                                                  {'loss': 1.4009, 'learning_rate': 1.15e-06, 'epoch': 0.05}
  5%|▌         | 41/753 [14:07<4:18:09, 21.76s/it]  6%|▌         | 42/753 [14:30<4:21:55, 22.10s/it]                                                  {'loss': 1.355, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.06}
  6%|▌         | 42/753 [14:30<4:21:55, 22.10s/it]  6%|▌         | 43/753 [14:52<4:21:00, 22.06s/it]                                                  {'loss': 1.4044, 'learning_rate': 1.2499999999999999e-06, 'epoch': 0.06}
  6%|▌         | 43/753 [14:52<4:21:00, 22.06s/it]  6%|▌         | 44/753 [15:15<4:24:19, 22.37s/it]                                                  {'loss': 1.3761, 'learning_rate': 1.3e-06, 'epoch': 0.06}
  6%|▌         | 44/753 [15:15<4:24:19, 22.37s/it]  6%|▌         | 45/753 [15:36<4:20:09, 22.05s/it]                                                  {'loss': 1.3694, 'learning_rate': 1.35e-06, 'epoch': 0.06}
  6%|▌         | 45/753 [15:36<4:20:09, 22.05s/it]  6%|▌         | 46/753 [15:59<4:19:55, 22.06s/it]                                                  {'loss': 1.3102, 'learning_rate': 1.4000000000000001e-06, 'epoch': 0.06}
  6%|▌         | 46/753 [15:59<4:19:55, 22.06s/it]  6%|▌         | 47/753 [16:22<4:22:44, 22.33s/it]                                                  {'loss': 1.2526, 'learning_rate': 1.45e-06, 'epoch': 0.06}
  6%|▌         | 47/753 [16:22<4:22:44, 22.33s/it]  6%|▋         | 48/753 [16:43<4:19:22, 22.07s/it]                                                  {'loss': 1.3005, 'learning_rate': 1.5e-06, 'epoch': 0.06}
  6%|▋         | 48/753 [16:43<4:19:22, 22.07s/it]  7%|▋         | 49/753 [17:06<4:21:22, 22.28s/it]                                                  {'loss': 1.2976, 'learning_rate': 1.55e-06, 'epoch': 0.07}
  7%|▋         | 49/753 [17:06<4:21:22, 22.28s/it]  7%|▋         | 50/753 [17:27<4:17:03, 21.94s/it]                                                  {'loss': 1.2178, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.07}
  7%|▋         | 50/753 [17:27<4:17:03, 21.94s/it]  7%|▋         | 51/753 [17:48<4:13:54, 21.70s/it]                                                  {'loss': 1.2657, 'learning_rate': 1.65e-06, 'epoch': 0.07}
  7%|▋         | 51/753 [17:48<4:13:54, 21.70s/it]  7%|▋         | 52/753 [18:09<4:12:26, 21.61s/it]                                                  {'loss': 1.2185, 'learning_rate': 1.7e-06, 'epoch': 0.07}
  7%|▋         | 52/753 [18:09<4:12:26, 21.61s/it]  7%|▋         | 53/753 [18:30<4:09:02, 21.35s/it]                                                  {'loss': 1.2246, 'learning_rate': 1.75e-06, 'epoch': 0.07}
  7%|▋         | 53/753 [18:30<4:09:02, 21.35s/it]  7%|▋         | 54/753 [18:52<4:11:00, 21.55s/it]                                                  {'loss': 1.2084, 'learning_rate': 1.8e-06, 'epoch': 0.07}
  7%|▋         | 54/753 [18:52<4:11:00, 21.55s/it]  7%|▋         | 55/753 [19:15<4:14:12, 21.85s/it]                                                  {'loss': 1.225, 'learning_rate': 1.85e-06, 'epoch': 0.07}
  7%|▋         | 55/753 [19:15<4:14:12, 21.85s/it]  7%|▋         | 56/753 [19:37<4:16:45, 22.10s/it]                                                  {'loss': 1.1975, 'learning_rate': 1.9000000000000002e-06, 'epoch': 0.07}
  7%|▋         | 56/753 [19:37<4:16:45, 22.10s/it]  8%|▊         | 57/753 [20:00<4:19:06, 22.34s/it]                                                  {'loss': 1.2303, 'learning_rate': 1.95e-06, 'epoch': 0.08}
  8%|▊         | 57/753 [20:00<4:19:06, 22.34s/it]  8%|▊         | 58/753 [20:23<4:19:27, 22.40s/it]                                                  {'loss': 1.2136, 'learning_rate': 2e-06, 'epoch': 0.08}
  8%|▊         | 58/753 [20:23<4:19:27, 22.40s/it]  8%|▊         | 59/753 [20:46<4:20:38, 22.53s/it]                                                  {'loss': 1.1733, 'learning_rate': 2.05e-06, 'epoch': 0.08}
  8%|▊         | 59/753 [20:46<4:20:38, 22.53s/it]  8%|▊         | 60/753 [21:08<4:17:54, 22.33s/it]                                                  {'loss': 1.1666, 'learning_rate': 2.1000000000000002e-06, 'epoch': 0.08}
  8%|▊         | 60/753 [21:08<4:17:54, 22.33s/it]  8%|▊         | 61/753 [21:31<4:21:12, 22.65s/it]                                                  {'loss': 1.1345, 'learning_rate': 2.15e-06, 'epoch': 0.08}
  8%|▊         | 61/753 [21:31<4:21:12, 22.65s/it]  8%|▊         | 62/753 [21:54<4:21:15, 22.69s/it]                                                  {'loss': 1.1898, 'learning_rate': 2.2e-06, 'epoch': 0.08}
  8%|▊         | 62/753 [21:54<4:21:15, 22.69s/it]  8%|▊         | 63/753 [22:16<4:20:48, 22.68s/it]                                                  {'loss': 1.1371, 'learning_rate': 2.25e-06, 'epoch': 0.08}
  8%|▊         | 63/753 [22:16<4:20:48, 22.68s/it]  8%|▊         | 64/753 [22:37<4:13:23, 22.07s/it]                                                  {'loss': 1.1274, 'learning_rate': 2.3e-06, 'epoch': 0.08}
  8%|▊         | 64/753 [22:37<4:13:23, 22.07s/it]  9%|▊         | 65/753 [22:58<4:08:40, 21.69s/it]                                                  {'loss': 1.0632, 'learning_rate': 2.3500000000000004e-06, 'epoch': 0.09}
  9%|▊         | 65/753 [22:58<4:08:40, 21.69s/it]  9%|▉         | 66/753 [23:21<4:13:13, 22.12s/it]                                                  {'loss': 1.1301, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.09}
  9%|▉         | 66/753 [23:21<4:13:13, 22.12s/it]  9%|▉         | 67/753 [23:43<4:12:40, 22.10s/it]                                                  {'loss': 1.1259, 'learning_rate': 2.45e-06, 'epoch': 0.09}
  9%|▉         | 67/753 [23:43<4:12:40, 22.10s/it]  9%|▉         | 68/753 [24:04<4:10:07, 21.91s/it]                                                  {'loss': 1.0809, 'learning_rate': 2.4999999999999998e-06, 'epoch': 0.09}
  9%|▉         | 68/753 [24:04<4:10:07, 21.91s/it]  9%|▉         | 69/753 [24:27<4:12:26, 22.14s/it]                                                  {'loss': 1.0763, 'learning_rate': 2.55e-06, 'epoch': 0.09}
  9%|▉         | 69/753 [24:27<4:12:26, 22.14s/it]  9%|▉         | 70/753 [24:51<4:16:14, 22.51s/it]                                                  {'loss': 1.0751, 'learning_rate': 2.6e-06, 'epoch': 0.09}
  9%|▉         | 70/753 [24:51<4:16:14, 22.51s/it]  9%|▉         | 71/753 [25:12<4:11:36, 22.14s/it]                                                  {'loss': 1.0935, 'learning_rate': 2.65e-06, 'epoch': 0.09}
  9%|▉         | 71/753 [25:12<4:11:36, 22.14s/it] 10%|▉         | 72/753 [25:33<4:06:49, 21.75s/it]                                                  {'loss': 1.101, 'learning_rate': 2.7e-06, 'epoch': 0.1}
 10%|▉         | 72/753 [25:33<4:06:49, 21.75s/it] 10%|▉         | 73/753 [25:54<4:06:54, 21.79s/it]                                                  {'loss': 1.1053, 'learning_rate': 2.75e-06, 'epoch': 0.1}
 10%|▉         | 73/753 [25:54<4:06:54, 21.79s/it] 10%|▉         | 74/753 [26:17<4:07:45, 21.89s/it]                                                  {'loss': 1.0604, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.1}
 10%|▉         | 74/753 [26:17<4:07:45, 21.89s/it] 10%|▉         | 75/753 [26:37<4:03:23, 21.54s/it]                                                  {'loss': 1.0828, 'learning_rate': 2.8500000000000002e-06, 'epoch': 0.1}
 10%|▉         | 75/753 [26:37<4:03:23, 21.54s/it] 10%|█         | 76/753 [26:58<4:01:36, 21.41s/it]                                                  {'loss': 1.0763, 'learning_rate': 2.9e-06, 'epoch': 0.1}
 10%|█         | 76/753 [26:58<4:01:36, 21.41s/it] 10%|█         | 77/753 [27:19<3:58:43, 21.19s/it]                                                  {'loss': 1.0759, 'learning_rate': 2.9499999999999997e-06, 'epoch': 0.1}
 10%|█         | 77/753 [27:19<3:58:43, 21.19s/it] 10%|█         | 78/753 [27:41<3:59:18, 21.27s/it]                                                  {'loss': 1.0568, 'learning_rate': 3e-06, 'epoch': 0.1}
 10%|█         | 78/753 [27:41<3:59:18, 21.27s/it] 10%|█         | 79/753 [28:02<3:59:21, 21.31s/it]                                                  {'loss': 1.0833, 'learning_rate': 3.05e-06, 'epoch': 0.1}
 10%|█         | 79/753 [28:02<3:59:21, 21.31s/it] 11%|█         | 80/753 [28:23<3:58:45, 21.29s/it]                                                  {'loss': 1.0884, 'learning_rate': 3.1e-06, 'epoch': 0.11}
 11%|█         | 80/753 [28:23<3:58:45, 21.29s/it] 11%|█         | 81/753 [28:46<4:02:21, 21.64s/it]                                                  {'loss': 1.0074, 'learning_rate': 3.15e-06, 'epoch': 0.11}
 11%|█         | 81/753 [28:46<4:02:21, 21.64s/it] 11%|█         | 82/753 [29:09<4:07:41, 22.15s/it]                                                  {'loss': 1.0263, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.11}
 11%|█         | 82/753 [29:09<4:07:41, 22.15s/it] 11%|█         | 83/753 [29:30<4:04:31, 21.90s/it]                                                  {'loss': 1.026, 'learning_rate': 3.2500000000000002e-06, 'epoch': 0.11}
 11%|█         | 83/753 [29:30<4:04:31, 21.90s/it] 11%|█         | 84/753 [29:52<4:02:36, 21.76s/it]                                                  {'loss': 1.0302, 'learning_rate': 3.3e-06, 'epoch': 0.11}
 11%|█         | 84/753 [29:52<4:02:36, 21.76s/it] 11%|█▏        | 85/753 [30:13<4:01:23, 21.68s/it]                                                  {'loss': 1.0134, 'learning_rate': 3.35e-06, 'epoch': 0.11}
 11%|█▏        | 85/753 [30:13<4:01:23, 21.68s/it] 11%|█▏        | 86/753 [30:35<3:59:38, 21.56s/it]                                                  {'loss': 0.9947, 'learning_rate': 3.4e-06, 'epoch': 0.11}
 11%|█▏        | 86/753 [30:35<3:59:38, 21.56s/it] 12%|█▏        | 87/753 [30:56<3:59:18, 21.56s/it]                                                  {'loss': 1.0485, 'learning_rate': 3.4500000000000004e-06, 'epoch': 0.12}
 12%|█▏        | 87/753 [30:56<3:59:18, 21.56s/it] 12%|█▏        | 88/753 [31:18<4:01:21, 21.78s/it]                                                  {'loss': 1.0146, 'learning_rate': 3.5e-06, 'epoch': 0.12}
 12%|█▏        | 88/753 [31:18<4:01:21, 21.78s/it] 12%|█▏        | 89/753 [31:41<4:02:58, 21.96s/it]                                                  {'loss': 1.041, 'learning_rate': 3.55e-06, 'epoch': 0.12}
 12%|█▏        | 89/753 [31:41<4:02:58, 21.96s/it] 12%|█▏        | 90/753 [32:03<4:04:10, 22.10s/it]                                                  {'loss': 0.9943, 'learning_rate': 3.6e-06, 'epoch': 0.12}
 12%|█▏        | 90/753 [32:03<4:04:10, 22.10s/it] 12%|█▏        | 91/753 [32:25<4:01:39, 21.90s/it]                                                  {'loss': 0.9757, 'learning_rate': 3.65e-06, 'epoch': 0.12}
 12%|█▏        | 91/753 [32:25<4:01:39, 21.90s/it] 12%|█▏        | 92/753 [32:47<4:04:16, 22.17s/it]                                                  {'loss': 0.9603, 'learning_rate': 3.7e-06, 'epoch': 0.12}
 12%|█▏        | 92/753 [32:47<4:04:16, 22.17s/it] 12%|█▏        | 93/753 [33:10<4:06:17, 22.39s/it]                                                  {'loss': 1.034, 'learning_rate': 3.75e-06, 'epoch': 0.12}
 12%|█▏        | 93/753 [33:10<4:06:17, 22.39s/it] 12%|█▏        | 94/753 [33:32<4:01:54, 22.02s/it]                                                  {'loss': 0.9956, 'learning_rate': 3.8000000000000005e-06, 'epoch': 0.12}
 12%|█▏        | 94/753 [33:32<4:01:54, 22.02s/it] 13%|█▎        | 95/753 [33:55<4:05:58, 22.43s/it]                                                  {'loss': 1.0083, 'learning_rate': 3.8499999999999996e-06, 'epoch': 0.13}
 13%|█▎        | 95/753 [33:55<4:05:58, 22.43s/it] 13%|█▎        | 96/753 [34:16<4:01:34, 22.06s/it]                                                  {'loss': 0.9564, 'learning_rate': 3.9e-06, 'epoch': 0.13}
 13%|█▎        | 96/753 [34:16<4:01:34, 22.06s/it] 13%|█▎        | 97/753 [34:38<4:01:31, 22.09s/it]                                                  {'loss': 1.0064, 'learning_rate': 3.9499999999999995e-06, 'epoch': 0.13}
 13%|█▎        | 97/753 [34:38<4:01:31, 22.09s/it] 13%|█▎        | 98/753 [35:01<4:02:15, 22.19s/it]                                                  {'loss': 0.9495, 'learning_rate': 4e-06, 'epoch': 0.13}
 13%|█▎        | 98/753 [35:01<4:02:15, 22.19s/it] 13%|█▎        | 99/753 [35:22<3:58:05, 21.84s/it]                                                  {'loss': 0.9394, 'learning_rate': 4.05e-06, 'epoch': 0.13}
 13%|█▎        | 99/753 [35:22<3:58:05, 21.84s/it] 13%|█▎        | 100/753 [35:44<3:57:47, 21.85s/it]                                                   {'loss': 0.9233, 'learning_rate': 4.1e-06, 'epoch': 0.13}
 13%|█▎        | 100/753 [35:44<3:57:47, 21.85s/it]/root/anaconda3/envs/unichat/lib/python3.10/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/root/anaconda3/envs/unichat/lib/python3.10/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/root/anaconda3/envs/unichat/lib/python3.10/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/root/anaconda3/envs/unichat/lib/python3.10/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/root/anaconda3/envs/unichat/lib/python3.10/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/root/anaconda3/envs/unichat/lib/python3.10/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/root/anaconda3/envs/unichat/lib/python3.10/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/root/anaconda3/envs/unichat/lib/python3.10/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
 13%|█▎        | 101/753 [39:28<14:57:01, 82.55s/it]                                                    {'loss': 0.9981, 'learning_rate': 4.15e-06, 'epoch': 0.13}
 13%|█▎        | 101/753 [39:28<14:57:01, 82.55s/it] 14%|█▎        | 102/753 [39:49<11:35:05, 64.06s/it]                                                    {'loss': 0.9472, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.14}
 14%|█▎        | 102/753 [39:49<11:35:05, 64.06s/it] 14%|█▎        | 103/753 [40:11<9:18:15, 51.53s/it]                                                    {'loss': 0.934, 'learning_rate': 4.25e-06, 'epoch': 0.14}
 14%|█▎        | 103/753 [40:11<9:18:15, 51.53s/it] 14%|█▍        | 104/753 [40:32<7:38:29, 42.39s/it]                                                   {'loss': 0.9362, 'learning_rate': 4.3e-06, 'epoch': 0.14}
 14%|█▍        | 104/753 [40:32<7:38:29, 42.39s/it] 14%|█▍        | 105/753 [40:53<6:28:30, 35.97s/it]                                                   {'loss': 0.9426, 'learning_rate': 4.35e-06, 'epoch': 0.14}
 14%|█▍        | 105/753 [40:53<6:28:30, 35.97s/it] 14%|█▍        | 106/753 [41:14<5:39:39, 31.50s/it]                                                   {'loss': 0.8892, 'learning_rate': 4.4e-06, 'epoch': 0.14}
 14%|█▍        | 106/753 [41:14<5:39:39, 31.50s/it] 14%|█▍        | 107/753 [41:36<5:09:31, 28.75s/it]                                                   {'loss': 0.9497, 'learning_rate': 4.450000000000001e-06, 'epoch': 0.14}
 14%|█▍        | 107/753 [41:36<5:09:31, 28.75s/it] 14%|█▍        | 108/753 [41:58<4:45:51, 26.59s/it]                                                   {'loss': 0.9114, 'learning_rate': 4.5e-06, 'epoch': 0.14}
 14%|█▍        | 108/753 [41:58<4:45:51, 26.59s/it] 14%|█▍        | 109/753 [42:20<4:30:08, 25.17s/it]                                                   {'loss': 0.9329, 'learning_rate': 4.5500000000000005e-06, 'epoch': 0.14}
 14%|█▍        | 109/753 [42:20<4:30:08, 25.17s/it] 15%|█▍        | 110/753 [42:41<4:16:38, 23.95s/it]                                                   {'loss': 0.8986, 'learning_rate': 4.6e-06, 'epoch': 0.15}
 15%|█▍        | 110/753 [42:41<4:16:38, 23.95s/it] 15%|█▍        | 111/753 [43:02<4:07:56, 23.17s/it]                                                   {'loss': 0.9437, 'learning_rate': 4.65e-06, 'epoch': 0.15}
 15%|█▍        | 111/753 [43:02<4:07:56, 23.17s/it] 15%|█▍        | 112/753 [43:24<4:03:14, 22.77s/it]                                                   {'loss': 0.8906, 'learning_rate': 4.700000000000001e-06, 'epoch': 0.15}
 15%|█▍        | 112/753 [43:24<4:03:14, 22.77s/it] 15%|█▌        | 113/753 [43:45<3:56:39, 22.19s/it]                                                   {'loss': 0.888, 'learning_rate': 4.75e-06, 'epoch': 0.15}
 15%|█▌        | 113/753 [43:45<3:56:39, 22.19s/it] 15%|█▌        | 114/753 [44:07<3:54:27, 22.02s/it]                                                   {'loss': 0.9363, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.15}
 15%|█▌        | 114/753 [44:07<3:54:27, 22.02s/it] 15%|█▌        | 115/753 [44:29<3:53:53, 22.00s/it]                                                   {'loss': 0.9065, 'learning_rate': 4.849999999999999e-06, 'epoch': 0.15}
 15%|█▌        | 115/753 [44:29<3:53:53, 22.00s/it] 15%|█▌        | 116/753 [44:50<3:52:54, 21.94s/it]                                                   {'loss': 0.8752, 'learning_rate': 4.9e-06, 'epoch': 0.15}
 15%|█▌        | 116/753 [44:50<3:52:54, 21.94s/it] 16%|█▌        | 117/753 [45:12<3:50:48, 21.77s/it]                                                   {'loss': 0.9224, 'learning_rate': 4.95e-06, 'epoch': 0.16}
 16%|█▌        | 117/753 [45:12<3:50:48, 21.77s/it] 16%|█▌        | 118/753 [45:34<3:53:26, 22.06s/it]                                                   {'loss': 0.8968, 'learning_rate': 4.9999999999999996e-06, 'epoch': 0.16}
 16%|█▌        | 118/753 [45:34<3:53:26, 22.06s/it] 16%|█▌        | 119/753 [45:55<3:49:01, 21.67s/it]                                                   {'loss': 0.9086, 'learning_rate': 5.05e-06, 'epoch': 0.16}
 16%|█▌        | 119/753 [45:55<3:49:01, 21.67s/it] 16%|█▌        | 120/753 [46:17<3:48:43, 21.68s/it]                                                   {'loss': 0.9424, 'learning_rate': 5.1e-06, 'epoch': 0.16}
 16%|█▌        | 120/753 [46:17<3:48:43, 21.68s/it] 16%|█▌        | 121/753 [46:39<3:49:22, 21.78s/it]                                                   {'loss': 0.9102, 'learning_rate': 5.15e-06, 'epoch': 0.16}
 16%|█▌        | 121/753 [46:39<3:49:22, 21.78s/it] 16%|█▌        | 122/753 [47:02<3:52:49, 22.14s/it]                                                   {'loss': 0.8717, 'learning_rate': 5.2e-06, 'epoch': 0.16}
 16%|█▌        | 122/753 [47:02<3:52:49, 22.14s/it] 16%|█▋        | 123/753 [47:23<3:48:55, 21.80s/it]                                                   {'loss': 0.9161, 'learning_rate': 5.25e-06, 'epoch': 0.16}
 16%|█▋        | 123/753 [47:23<3:48:55, 21.80s/it] 16%|█▋        | 124/753 [47:46<3:52:11, 22.15s/it]                                                   {'loss': 0.9338, 'learning_rate': 5.3e-06, 'epoch': 0.16}
 16%|█▋        | 124/753 [47:46<3:52:11, 22.15s/it] 17%|█▋        | 125/753 [48:08<3:51:24, 22.11s/it]                                                   {'loss': 0.9518, 'learning_rate': 5.3500000000000004e-06, 'epoch': 0.17}
 17%|█▋        | 125/753 [48:08<3:51:24, 22.11s/it] 17%|█▋        | 126/753 [48:30<3:52:39, 22.26s/it]                                                   {'loss': 0.9077, 'learning_rate': 5.4e-06, 'epoch': 0.17}
 17%|█▋        | 126/753 [48:31<3:52:39, 22.26s/it] 17%|█▋        | 127/753 [48:51<3:48:10, 21.87s/it]                                                   {'loss': 0.8671, 'learning_rate': 5.45e-06, 'epoch': 0.17}
 17%|█▋        | 127/753 [48:51<3:48:10, 21.87s/it] 17%|█▋        | 128/753 [49:14<3:49:19, 22.01s/it]                                                   {'loss': 0.8946, 'learning_rate': 5.5e-06, 'epoch': 0.17}
 17%|█▋        | 128/753 [49:14<3:49:19, 22.01s/it] 17%|█▋        | 129/753 [49:35<3:45:49, 21.71s/it]                                                   {'loss': 0.8599, 'learning_rate': 5.55e-06, 'epoch': 0.17}
 17%|█▋        | 129/753 [49:35<3:45:49, 21.71s/it] 17%|█▋        | 130/753 [49:57<3:47:46, 21.94s/it]                                                   {'loss': 0.9058, 'learning_rate': 5.600000000000001e-06, 'epoch': 0.17}
 17%|█▋        | 130/753 [49:57<3:47:46, 21.94s/it] 17%|█▋        | 131/753 [50:19<3:46:59, 21.90s/it]                                                   {'loss': 0.8793, 'learning_rate': 5.65e-06, 'epoch': 0.17}
 17%|█▋        | 131/753 [50:19<3:46:59, 21.90s/it] 18%|█▊        | 132/753 [50:41<3:46:30, 21.88s/it]                                                   {'loss': 0.9185, 'learning_rate': 5.7000000000000005e-06, 'epoch': 0.18}
 18%|█▊        | 132/753 [50:41<3:46:30, 21.88s/it] 18%|█▊        | 133/753 [51:03<3:46:48, 21.95s/it]                                                   {'loss': 0.8415, 'learning_rate': 5.750000000000001e-06, 'epoch': 0.18}
 18%|█▊        | 133/753 [51:03<3:46:48, 21.95s/it] 18%|█▊        | 134/753 [51:24<3:42:45, 21.59s/it]                                                   {'loss': 0.8644, 'learning_rate': 5.8e-06, 'epoch': 0.18}
 18%|█▊        | 134/753 [51:24<3:42:45, 21.59s/it] 18%|█▊        | 135/753 [51:46<3:43:21, 21.68s/it]                                                   {'loss': 0.8907, 'learning_rate': 5.850000000000001e-06, 'epoch': 0.18}
 18%|█▊        | 135/753 [51:46<3:43:21, 21.68s/it] 18%|█▊        | 136/753 [52:07<3:43:01, 21.69s/it]                                                   {'loss': 0.8998, 'learning_rate': 5.899999999999999e-06, 'epoch': 0.18}
 18%|█▊        | 136/753 [52:07<3:43:01, 21.69s/it] 18%|█▊        | 137/753 [52:30<3:46:24, 22.05s/it]                                                   {'loss': 0.8611, 'learning_rate': 5.95e-06, 'epoch': 0.18}
 18%|█▊        | 137/753 [52:30<3:46:24, 22.05s/it] 18%|█▊        | 138/753 [52:51<3:42:25, 21.70s/it]                                                   {'loss': 0.8341, 'learning_rate': 6e-06, 'epoch': 0.18}
 18%|█▊        | 138/753 [52:51<3:42:25, 21.70s/it] 18%|█▊        | 139/753 [53:13<3:41:18, 21.63s/it]                                                   {'loss': 0.8961, 'learning_rate': 6.05e-06, 'epoch': 0.18}
 18%|█▊        | 139/753 [53:13<3:41:18, 21.63s/it] 19%|█▊        | 140/753 [53:34<3:41:33, 21.69s/it]                                                   {'loss': 0.8633, 'learning_rate': 6.1e-06, 'epoch': 0.19}
 19%|█▊        | 140/753 [53:34<3:41:33, 21.69s/it] 19%|█▊        | 141/753 [53:56<3:39:17, 21.50s/it]                                                   {'loss': 0.888, 'learning_rate': 6.1499999999999996e-06, 'epoch': 0.19}
 19%|█▊        | 141/753 [53:56<3:39:17, 21.50s/it] 19%|█▉        | 142/753 [54:17<3:38:34, 21.46s/it]                                                   {'loss': 0.8064, 'learning_rate': 6.2e-06, 'epoch': 0.19}
 19%|█▉        | 142/753 [54:17<3:38:34, 21.46s/it] 19%|█▉        | 143/753 [54:38<3:35:46, 21.22s/it]                                                   {'loss': 0.8427, 'learning_rate': 6.25e-06, 'epoch': 0.19}
 19%|█▉        | 143/753 [54:38<3:35:46, 21.22s/it] 19%|█▉        | 144/753 [54:59<3:35:30, 21.23s/it]                                                   {'loss': 0.8757, 'learning_rate': 6.3e-06, 'epoch': 0.19}
 19%|█▉        | 144/753 [54:59<3:35:30, 21.23s/it] 19%|█▉        | 145/753 [55:21<3:37:02, 21.42s/it]                                                   {'loss': 0.8176, 'learning_rate': 6.35e-06, 'epoch': 0.19}
 19%|█▉        | 145/753 [55:21<3:37:02, 21.42s/it] 19%|█▉        | 146/753 [55:43<3:40:14, 21.77s/it]                                                   {'loss': 0.8368, 'learning_rate': 6.4000000000000006e-06, 'epoch': 0.19}
 19%|█▉        | 146/753 [55:43<3:40:14, 21.77s/it] 20%|█▉        | 147/753 [56:06<3:42:41, 22.05s/it]                                                   {'loss': 0.9005, 'learning_rate': 6.45e-06, 'epoch': 0.2}
 20%|█▉        | 147/753 [56:06<3:42:41, 22.05s/it] 20%|█▉        | 148/753 [56:27<3:38:19, 21.65s/it]                                                   {'loss': 0.821, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.2}
 20%|█▉        | 148/753 [56:27<3:38:19, 21.65s/it] 20%|█▉        | 149/753 [56:48<3:36:17, 21.49s/it]                                                   {'loss': 0.8547, 'learning_rate': 6.55e-06, 'epoch': 0.2}
 20%|█▉        | 149/753 [56:48<3:36:17, 21.49s/it] 20%|█▉        | 150/753 [57:09<3:36:22, 21.53s/it]                                                   {'loss': 0.8939, 'learning_rate': 6.6e-06, 'epoch': 0.2}
 20%|█▉        | 150/753 [57:09<3:36:22, 21.53s/it] 20%|██        | 151/753 [57:32<3:38:48, 21.81s/it]                                                   {'loss': 0.8474, 'learning_rate': 6.650000000000001e-06, 'epoch': 0.2}
 20%|██        | 151/753 [57:32<3:38:48, 21.81s/it] 20%|██        | 152/753 [57:53<3:36:28, 21.61s/it]                                                   {'loss': 0.8128, 'learning_rate': 6.7e-06, 'epoch': 0.2}
 20%|██        | 152/753 [57:53<3:36:28, 21.61s/it] 20%|██        | 153/753 [58:14<3:34:50, 21.48s/it]                                                   {'loss': 0.8117, 'learning_rate': 6.750000000000001e-06, 'epoch': 0.2}
 20%|██        | 153/753 [58:14<3:34:50, 21.48s/it] 20%|██        | 154/753 [58:35<3:32:54, 21.33s/it]                                                   {'loss': 0.8426, 'learning_rate': 6.8e-06, 'epoch': 0.2}
 20%|██        | 154/753 [58:35<3:32:54, 21.33s/it] 21%|██        | 155/753 [58:57<3:32:58, 21.37s/it]                                                   {'loss': 0.8114, 'learning_rate': 6.8500000000000005e-06, 'epoch': 0.21}
 21%|██        | 155/753 [58:57<3:32:58, 21.37s/it] 21%|██        | 156/753 [59:19<3:35:40, 21.68s/it]                                                   {'loss': 0.8387, 'learning_rate': 6.900000000000001e-06, 'epoch': 0.21}
 21%|██        | 156/753 [59:19<3:35:40, 21.68s/it] 21%|██        | 157/753 [59:41<3:35:57, 21.74s/it]                                                   {'loss': 0.8658, 'learning_rate': 6.95e-06, 'epoch': 0.21}
 21%|██        | 157/753 [59:41<3:35:57, 21.74s/it] 21%|██        | 158/753 [1:00:02<3:33:11, 21.50s/it]                                                     {'loss': 0.7641, 'learning_rate': 7e-06, 'epoch': 0.21}
 21%|██        | 158/753 [1:00:02<3:33:11, 21.50s/it] 21%|██        | 159/753 [1:00:23<3:32:30, 21.47s/it]                                                     {'loss': 0.8654, 'learning_rate': 7.049999999999999e-06, 'epoch': 0.21}
 21%|██        | 159/753 [1:00:23<3:32:30, 21.47s/it] 21%|██        | 160/753 [1:00:46<3:35:11, 21.77s/it]                                                     {'loss': 0.8358, 'learning_rate': 7.1e-06, 'epoch': 0.21}
 21%|██        | 160/753 [1:00:46<3:35:11, 21.77s/it] 21%|██▏       | 161/753 [1:01:08<3:36:47, 21.97s/it]                                                     {'loss': 0.8835, 'learning_rate': 7.15e-06, 'epoch': 0.21}
 21%|██▏       | 161/753 [1:01:08<3:36:47, 21.97s/it] 22%|██▏       | 162/753 [1:01:29<3:33:31, 21.68s/it]                                                     {'loss': 0.8873, 'learning_rate': 7.2e-06, 'epoch': 0.22}
 22%|██▏       | 162/753 [1:01:29<3:33:31, 21.68s/it] 22%|██▏       | 163/753 [1:01:50<3:31:26, 21.50s/it]                                                     {'loss': 0.8116, 'learning_rate': 7.25e-06, 'epoch': 0.22}
 22%|██▏       | 163/753 [1:01:50<3:31:26, 21.50s/it] 22%|██▏       | 164/753 [1:02:12<3:32:20, 21.63s/it]                                                     {'loss': 0.8276, 'learning_rate': 7.3e-06, 'epoch': 0.22}
 22%|██▏       | 164/753 [1:02:12<3:32:20, 21.63s/it] 22%|██▏       | 165/753 [1:02:33<3:29:09, 21.34s/it]                                                     {'loss': 0.8022, 'learning_rate': 7.35e-06, 'epoch': 0.22}
 22%|██▏       | 165/753 [1:02:33<3:29:09, 21.34s/it] 22%|██▏       | 166/753 [1:02:54<3:28:38, 21.33s/it]                                                     {'loss': 0.8199, 'learning_rate': 7.4e-06, 'epoch': 0.22}
 22%|██▏       | 166/753 [1:02:54<3:28:38, 21.33s/it] 22%|██▏       | 167/753 [1:03:15<3:26:45, 21.17s/it]                                                     {'loss': 0.8448, 'learning_rate': 7.45e-06, 'epoch': 0.22}
 22%|██▏       | 167/753 [1:03:15<3:26:45, 21.17s/it] 22%|██▏       | 168/753 [1:03:37<3:27:34, 21.29s/it]                                                     {'loss': 0.872, 'learning_rate': 7.5e-06, 'epoch': 0.22}
 22%|██▏       | 168/753 [1:03:37<3:27:34, 21.29s/it] 22%|██▏       | 169/753 [1:03:59<3:29:42, 21.55s/it]                                                     {'loss': 0.8106, 'learning_rate': 7.55e-06, 'epoch': 0.22}
 22%|██▏       | 169/753 [1:03:59<3:29:42, 21.55s/it] 23%|██▎       | 170/753 [1:04:21<3:31:50, 21.80s/it]                                                     {'loss': 0.8597, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.23}
 23%|██▎       | 170/753 [1:04:21<3:31:50, 21.80s/it] 23%|██▎       | 171/753 [1:04:42<3:28:48, 21.53s/it]                                                     {'loss': 0.8987, 'learning_rate': 7.65e-06, 'epoch': 0.23}
 23%|██▎       | 171/753 [1:04:42<3:28:48, 21.53s/it] 23%|██▎       | 172/753 [1:05:03<3:28:29, 21.53s/it]                                                     {'loss': 0.7985, 'learning_rate': 7.699999999999999e-06, 'epoch': 0.23}
 23%|██▎       | 172/753 [1:05:03<3:28:29, 21.53s/it] 23%|██▎       | 173/753 [1:05:26<3:30:05, 21.73s/it]                                                     {'loss': 0.8767, 'learning_rate': 7.75e-06, 'epoch': 0.23}
 23%|██▎       | 173/753 [1:05:26<3:30:05, 21.73s/it] 23%|██▎       | 174/753 [1:05:47<3:29:19, 21.69s/it]                                                     {'loss': 0.7957, 'learning_rate': 7.8e-06, 'epoch': 0.23}
 23%|██▎       | 174/753 [1:05:47<3:29:19, 21.69s/it] 23%|██▎       | 175/753 [1:06:09<3:27:49, 21.57s/it]                                                     {'loss': 0.8722, 'learning_rate': 7.85e-06, 'epoch': 0.23}
 23%|██▎       | 175/753 [1:06:09<3:27:49, 21.57s/it] 23%|██▎       | 176/753 [1:06:31<3:29:05, 21.74s/it]                                                     {'loss': 0.8802, 'learning_rate': 7.899999999999999e-06, 'epoch': 0.23}
 23%|██▎       | 176/753 [1:06:31<3:29:05, 21.74s/it] 24%|██▎       | 177/753 [1:06:52<3:28:34, 21.73s/it]                                                     {'loss': 0.8506, 'learning_rate': 7.95e-06, 'epoch': 0.24}
 24%|██▎       | 177/753 [1:06:52<3:28:34, 21.73s/it] 24%|██▎       | 178/753 [1:07:13<3:26:17, 21.53s/it]                                                     {'loss': 0.8262, 'learning_rate': 8e-06, 'epoch': 0.24}
 24%|██▎       | 178/753 [1:07:13<3:26:17, 21.53s/it] 24%|██▍       | 179/753 [1:07:35<3:26:29, 21.58s/it]                                                     {'loss': 0.8297, 'learning_rate': 8.05e-06, 'epoch': 0.24}
 24%|██▍       | 179/753 [1:07:35<3:26:29, 21.58s/it] 24%|██▍       | 180/753 [1:07:57<3:27:39, 21.74s/it]                                                     {'loss': 0.8116, 'learning_rate': 8.1e-06, 'epoch': 0.24}
 24%|██▍       | 180/753 [1:07:57<3:27:39, 21.74s/it] 24%|██▍       | 181/753 [1:08:21<3:31:43, 22.21s/it]                                                     {'loss': 0.7556, 'learning_rate': 8.15e-06, 'epoch': 0.24}
 24%|██▍       | 181/753 [1:08:21<3:31:43, 22.21s/it] 24%|██▍       | 182/753 [1:08:42<3:28:42, 21.93s/it]                                                     {'loss': 0.7924, 'learning_rate': 8.2e-06, 'epoch': 0.24}
 24%|██▍       | 182/753 [1:08:42<3:28:42, 21.93s/it] 24%|██▍       | 183/753 [1:09:03<3:26:05, 21.69s/it]                                                     {'loss': 0.7802, 'learning_rate': 8.25e-06, 'epoch': 0.24}
 24%|██▍       | 183/753 [1:09:03<3:26:05, 21.69s/it] 24%|██▍       | 184/753 [1:09:25<3:26:44, 21.80s/it]                                                     {'loss': 0.8307, 'learning_rate': 8.3e-06, 'epoch': 0.24}
 24%|██▍       | 184/753 [1:09:25<3:26:44, 21.80s/it] 25%|██▍       | 185/753 [1:09:48<3:29:10, 22.10s/it]                                                     {'loss': 0.8125, 'learning_rate': 8.35e-06, 'epoch': 0.25}
 25%|██▍       | 185/753 [1:09:48<3:29:10, 22.10s/it] 25%|██▍       | 186/753 [1:10:10<3:29:43, 22.19s/it]                                                     {'loss': 0.8679, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.25}
 25%|██▍       | 186/753 [1:10:10<3:29:43, 22.19s/it] 25%|██▍       | 187/753 [1:10:31<3:25:55, 21.83s/it]                                                     {'loss': 0.8232, 'learning_rate': 8.45e-06, 'epoch': 0.25}
 25%|██▍       | 187/753 [1:10:31<3:25:55, 21.83s/it] 25%|██▍       | 188/753 [1:10:54<3:29:21, 22.23s/it]                                                     {'loss': 0.8575, 'learning_rate': 8.5e-06, 'epoch': 0.25}
 25%|██▍       | 188/753 [1:10:54<3:29:21, 22.23s/it] 25%|██▌       | 189/753 [1:11:16<3:26:26, 21.96s/it]                                                     {'loss': 0.8389, 'learning_rate': 8.55e-06, 'epoch': 0.25}
 25%|██▌       | 189/753 [1:11:16<3:26:26, 21.96s/it] 25%|██▌       | 190/753 [1:11:38<3:28:11, 22.19s/it]                                                     {'loss': 0.8485, 'learning_rate': 8.6e-06, 'epoch': 0.25}
 25%|██▌       | 190/753 [1:11:38<3:28:11, 22.19s/it] 25%|██▌       | 191/753 [1:12:00<3:26:11, 22.01s/it]                                                     {'loss': 0.8458, 'learning_rate': 8.65e-06, 'epoch': 0.25}
 25%|██▌       | 191/753 [1:12:00<3:26:11, 22.01s/it] 25%|██▌       | 192/753 [1:12:23<3:27:04, 22.15s/it]                                                     {'loss': 0.8749, 'learning_rate': 8.7e-06, 'epoch': 0.25}
 25%|██▌       | 192/753 [1:12:23<3:27:04, 22.15s/it] 26%|██▌       | 193/753 [1:12:44<3:25:17, 21.99s/it]                                                     {'loss': 0.8358, 'learning_rate': 8.750000000000001e-06, 'epoch': 0.26}
 26%|██▌       | 193/753 [1:12:44<3:25:17, 21.99s/it] 26%|██▌       | 194/753 [1:13:05<3:21:18, 21.61s/it]                                                     {'loss': 0.8464, 'learning_rate': 8.8e-06, 'epoch': 0.26}
 26%|██▌       | 194/753 [1:13:05<3:21:18, 21.61s/it] 26%|██▌       | 195/753 [1:13:26<3:19:30, 21.45s/it]                                                     {'loss': 0.8205, 'learning_rate': 8.85e-06, 'epoch': 0.26}
 26%|██▌       | 195/753 [1:13:26<3:19:30, 21.45s/it] 26%|██▌       | 196/753 [1:13:48<3:21:18, 21.69s/it]                                                     {'loss': 0.8074, 'learning_rate': 8.900000000000001e-06, 'epoch': 0.26}
 26%|██▌       | 196/753 [1:13:48<3:21:18, 21.69s/it] 26%|██▌       | 197/753 [1:14:09<3:17:12, 21.28s/it]                                                     {'loss': 0.8115, 'learning_rate': 8.95e-06, 'epoch': 0.26}
 26%|██▌       | 197/753 [1:14:09<3:17:12, 21.28s/it] 26%|██▋       | 198/753 [1:14:29<3:15:29, 21.13s/it]                                                     {'loss': 0.7653, 'learning_rate': 9e-06, 'epoch': 0.26}
 26%|██▋       | 198/753 [1:14:29<3:15:29, 21.13s/it] 26%|██▋       | 199/753 [1:14:52<3:20:36, 21.73s/it]                                                     {'loss': 0.7852, 'learning_rate': 9.050000000000001e-06, 'epoch': 0.26}
 26%|██▋       | 199/753 [1:14:52<3:20:36, 21.73s/it] 27%|██▋       | 200/753 [1:15:11<3:12:21, 20.87s/it]                                                     {'loss': 0.834, 'learning_rate': 9.100000000000001e-06, 'epoch': 0.27}
 27%|██▋       | 200/753 [1:15:11<3:12:21, 20.87s/it] 27%|██▋       | 201/753 [1:19:25<13:54:19, 90.69s/it]                                                      {'loss': 0.8137, 'learning_rate': 9.15e-06, 'epoch': 0.27}
 27%|██▋       | 201/753 [1:19:25<13:54:19, 90.69s/it] 27%|██▋       | 202/753 [1:19:46<10:41:54, 69.90s/it]                                                      {'loss': 0.8141, 'learning_rate': 9.2e-06, 'epoch': 0.27}
 27%|██▋       | 202/753 [1:19:46<10:41:54, 69.90s/it] 27%|██▋       | 203/753 [1:20:08<8:27:12, 55.33s/it]                                                      {'loss': 0.7911, 'learning_rate': 9.250000000000001e-06, 'epoch': 0.27}
 27%|██▋       | 203/753 [1:20:08<8:27:12, 55.33s/it] 27%|██▋       | 204/753 [1:20:29<6:52:18, 45.06s/it]                                                     {'loss': 0.814, 'learning_rate': 9.3e-06, 'epoch': 0.27}
 27%|██▋       | 204/753 [1:20:29<6:52:18, 45.06s/it] 27%|██▋       | 205/753 [1:20:50<5:46:15, 37.91s/it]                                                     {'loss': 0.7325, 'learning_rate': 9.35e-06, 'epoch': 0.27}
 27%|██▋       | 205/753 [1:20:50<5:46:15, 37.91s/it] 27%|██▋       | 206/753 [1:21:12<5:02:54, 33.23s/it]                                                     {'loss': 0.824, 'learning_rate': 9.400000000000001e-06, 'epoch': 0.27}
 27%|██▋       | 206/753 [1:21:12<5:02:54, 33.23s/it] 27%|██▋       | 207/753 [1:21:33<4:27:06, 29.35s/it]                                                     {'loss': 0.8216, 'learning_rate': 9.450000000000001e-06, 'epoch': 0.27}
 27%|██▋       | 207/753 [1:21:33<4:27:06, 29.35s/it] 28%|██▊       | 208/753 [1:21:54<4:04:21, 26.90s/it]                                                     {'loss': 0.863, 'learning_rate': 9.5e-06, 'epoch': 0.28}
 28%|██▊       | 208/753 [1:21:54<4:04:21, 26.90s/it] 28%|██▊       | 209/753 [1:22:15<3:48:12, 25.17s/it]                                                     {'loss': 0.7825, 'learning_rate': 9.550000000000002e-06, 'epoch': 0.28}
 28%|██▊       | 209/753 [1:22:15<3:48:12, 25.17s/it] 28%|██▊       | 210/753 [1:22:37<3:38:13, 24.11s/it]                                                     {'loss': 0.7653, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.28}
 28%|██▊       | 210/753 [1:22:37<3:38:13, 24.11s/it] 28%|██▊       | 211/753 [1:22:58<3:30:11, 23.27s/it]                                                     {'loss': 0.8013, 'learning_rate': 9.649999999999999e-06, 'epoch': 0.28}
 28%|██▊       | 211/753 [1:22:58<3:30:11, 23.27s/it] 28%|██▊       | 212/753 [1:23:21<3:29:35, 23.25s/it]                                                     {'loss': 0.8273, 'learning_rate': 9.699999999999999e-06, 'epoch': 0.28}
 28%|██▊       | 212/753 [1:23:21<3:29:35, 23.25s/it] 28%|██▊       | 213/753 [1:23:42<3:24:22, 22.71s/it]                                                     {'loss': 0.7542, 'learning_rate': 9.75e-06, 'epoch': 0.28}
 28%|██▊       | 213/753 [1:23:42<3:24:22, 22.71s/it] 28%|██▊       | 214/753 [1:24:03<3:19:12, 22.17s/it]                                                     {'loss': 0.8203, 'learning_rate': 9.8e-06, 'epoch': 0.28}
 28%|██▊       | 214/753 [1:24:03<3:19:12, 22.17s/it] 29%|██▊       | 215/753 [1:24:25<3:16:43, 21.94s/it]                                                     {'loss': 0.8655, 'learning_rate': 9.849999999999999e-06, 'epoch': 0.29}
 29%|██▊       | 215/753 [1:24:25<3:16:43, 21.94s/it] 29%|██▊       | 216/753 [1:24:46<3:13:49, 21.66s/it]                                                     {'loss': 0.7731, 'learning_rate': 9.9e-06, 'epoch': 0.29}
 29%|██▊       | 216/753 [1:24:46<3:13:49, 21.66s/it] 29%|██▉       | 217/753 [1:25:09<3:17:12, 22.08s/it]                                                     {'loss': 0.7825, 'learning_rate': 9.95e-06, 'epoch': 0.29}
 29%|██▉       | 217/753 [1:25:09<3:17:12, 22.08s/it] 29%|██▉       | 218/753 [1:25:30<3:14:27, 21.81s/it]                                                     {'loss': 0.7593, 'learning_rate': 9.999999999999999e-06, 'epoch': 0.29}
 29%|██▉       | 218/753 [1:25:30<3:14:27, 21.81s/it] 29%|██▉       | 219/753 [1:25:53<3:16:16, 22.05s/it]                                                     {'loss': 0.7619, 'learning_rate': 1.005e-05, 'epoch': 0.29}
 29%|██▉       | 219/753 [1:25:53<3:16:16, 22.05s/it] 29%|██▉       | 220/753 [1:26:14<3:14:34, 21.90s/it]                                                     {'loss': 0.8424, 'learning_rate': 1.01e-05, 'epoch': 0.29}
 29%|██▉       | 220/753 [1:26:14<3:14:34, 21.90s/it] 29%|██▉       | 221/753 [1:26:37<3:17:24, 22.26s/it]                                                     {'loss': 0.8007, 'learning_rate': 1.015e-05, 'epoch': 0.29}
 29%|██▉       | 221/753 [1:26:37<3:17:24, 22.26s/it] 29%|██▉       | 222/753 [1:27:01<3:19:48, 22.58s/it]                                                     {'loss': 0.7874, 'learning_rate': 1.02e-05, 'epoch': 0.29}
 29%|██▉       | 222/753 [1:27:01<3:19:48, 22.58s/it] 30%|██▉       | 223/753 [1:27:22<3:15:25, 22.12s/it]                                                     {'loss': 0.8057, 'learning_rate': 1.025e-05, 'epoch': 0.3}
 30%|██▉       | 223/753 [1:27:22<3:15:25, 22.12s/it] 30%|██▉       | 224/753 [1:27:42<3:11:02, 21.67s/it]                                                     {'loss': 0.7789, 'learning_rate': 1.03e-05, 'epoch': 0.3}
 30%|██▉       | 224/753 [1:27:42<3:11:02, 21.67s/it] 30%|██▉       | 225/753 [1:28:04<3:10:47, 21.68s/it]                                                     {'loss': 0.817, 'learning_rate': 1.035e-05, 'epoch': 0.3}
 30%|██▉       | 225/753 [1:28:04<3:10:47, 21.68s/it] 30%|███       | 226/753 [1:28:26<3:11:19, 21.78s/it]                                                     {'loss': 0.7325, 'learning_rate': 1.04e-05, 'epoch': 0.3}
 30%|███       | 226/753 [1:28:26<3:11:19, 21.78s/it] 30%|███       | 227/753 [1:28:48<3:10:42, 21.75s/it]                                                     {'loss': 0.7618, 'learning_rate': 1.045e-05, 'epoch': 0.3}
 30%|███       | 227/753 [1:28:48<3:10:42, 21.75s/it] 30%|███       | 228/753 [1:29:09<3:08:25, 21.54s/it]                                                     {'loss': 0.8255, 'learning_rate': 1.05e-05, 'epoch': 0.3}
 30%|███       | 228/753 [1:29:09<3:08:25, 21.54s/it] 30%|███       | 229/753 [1:29:30<3:06:23, 21.34s/it]                                                     {'loss': 0.7917, 'learning_rate': 1.055e-05, 'epoch': 0.3}
 30%|███       | 229/753 [1:29:30<3:06:23, 21.34s/it] 31%|███       | 230/753 [1:29:51<3:06:29, 21.39s/it]                                                     {'loss': 0.8129, 'learning_rate': 1.06e-05, 'epoch': 0.31}
 31%|███       | 230/753 [1:29:51<3:06:29, 21.39s/it] 31%|███       | 231/753 [1:30:12<3:05:16, 21.30s/it]                                                     {'loss': 0.7538, 'learning_rate': 1.065e-05, 'epoch': 0.31}
 31%|███       | 231/753 [1:30:12<3:05:16, 21.30s/it] 31%|███       | 232/753 [1:30:33<3:02:20, 21.00s/it]                                                     {'loss': 0.7729, 'learning_rate': 1.0700000000000001e-05, 'epoch': 0.31}
 31%|███       | 232/753 [1:30:33<3:02:20, 21.00s/it] 31%|███       | 233/753 [1:30:55<3:05:18, 21.38s/it]                                                     {'loss': 0.7755, 'learning_rate': 1.075e-05, 'epoch': 0.31}
 31%|███       | 233/753 [1:30:55<3:05:18, 21.38s/it] 31%|███       | 234/753 [1:31:16<3:04:09, 21.29s/it]                                                     {'loss': 0.7944, 'learning_rate': 1.08e-05, 'epoch': 0.31}
 31%|███       | 234/753 [1:31:16<3:04:09, 21.29s/it] 31%|███       | 235/753 [1:31:39<3:07:47, 21.75s/it]                                                     {'loss': 0.8242, 'learning_rate': 1.0850000000000001e-05, 'epoch': 0.31}
 31%|███       | 235/753 [1:31:39<3:07:47, 21.75s/it] 31%|███▏      | 236/753 [1:32:02<3:11:49, 22.26s/it]                                                     {'loss': 0.7626, 'learning_rate': 1.09e-05, 'epoch': 0.31}
 31%|███▏      | 236/753 [1:32:02<3:11:49, 22.26s/it] 31%|███▏      | 237/753 [1:32:25<3:13:29, 22.50s/it]                                                     {'loss': 0.7253, 'learning_rate': 1.095e-05, 'epoch': 0.31}
 31%|███▏      | 237/753 [1:32:25<3:13:29, 22.50s/it] 32%|███▏      | 238/753 [1:32:46<3:09:36, 22.09s/it]                                                     {'loss': 0.8119, 'learning_rate': 1.1e-05, 'epoch': 0.32}
 32%|███▏      | 238/753 [1:32:46<3:09:36, 22.09s/it] 32%|███▏      | 239/753 [1:33:08<3:07:25, 21.88s/it]                                                     {'loss': 0.7544, 'learning_rate': 1.1050000000000001e-05, 'epoch': 0.32}
 32%|███▏      | 239/753 [1:33:08<3:07:25, 21.88s/it] 32%|███▏      | 240/753 [1:33:29<3:05:28, 21.69s/it]                                                     {'loss': 0.8004, 'learning_rate': 1.11e-05, 'epoch': 0.32}
 32%|███▏      | 240/753 [1:33:29<3:05:28, 21.69s/it] 32%|███▏      | 241/753 [1:33:50<3:04:14, 21.59s/it]                                                     {'loss': 0.7729, 'learning_rate': 1.115e-05, 'epoch': 0.32}
 32%|███▏      | 241/753 [1:33:50<3:04:14, 21.59s/it] 32%|███▏      | 242/753 [1:34:13<3:07:21, 22.00s/it]                                                     {'loss': 0.7338, 'learning_rate': 1.1200000000000001e-05, 'epoch': 0.32}
 32%|███▏      | 242/753 [1:34:13<3:07:21, 22.00s/it] 32%|███▏      | 243/753 [1:34:35<3:06:50, 21.98s/it]                                                     {'loss': 0.8226, 'learning_rate': 1.125e-05, 'epoch': 0.32}
 32%|███▏      | 243/753 [1:34:35<3:06:50, 21.98s/it] 32%|███▏      | 244/753 [1:34:57<3:04:55, 21.80s/it]                                                     {'loss': 0.7419, 'learning_rate': 1.13e-05, 'epoch': 0.32}
 32%|███▏      | 244/753 [1:34:57<3:04:55, 21.80s/it] 33%|███▎      | 245/753 [1:35:18<3:02:53, 21.60s/it]                                                     {'loss': 0.7668, 'learning_rate': 1.1350000000000001e-05, 'epoch': 0.33}
 33%|███▎      | 245/753 [1:35:18<3:02:53, 21.60s/it] 33%|███▎      | 246/753 [1:35:39<3:00:56, 21.41s/it]                                                     {'loss': 0.7719, 'learning_rate': 1.1400000000000001e-05, 'epoch': 0.33}
 33%|███▎      | 246/753 [1:35:39<3:00:56, 21.41s/it] 33%|███▎      | 247/753 [1:36:01<3:02:03, 21.59s/it]                                                     {'loss': 0.7623, 'learning_rate': 1.145e-05, 'epoch': 0.33}
 33%|███▎      | 247/753 [1:36:01<3:02:03, 21.59s/it] 33%|███▎      | 248/753 [1:36:22<3:00:45, 21.48s/it]                                                     {'loss': 0.7372, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.33}
 33%|███▎      | 248/753 [1:36:22<3:00:45, 21.48s/it] 33%|███▎      | 249/753 [1:36:44<3:01:41, 21.63s/it]                                                     {'loss': 0.7817, 'learning_rate': 1.1550000000000001e-05, 'epoch': 0.33}
 33%|███▎      | 249/753 [1:36:44<3:01:41, 21.63s/it] 33%|███▎      | 250/753 [1:37:05<2:59:52, 21.46s/it]                                                     {'loss': 0.7943, 'learning_rate': 1.16e-05, 'epoch': 0.33}
 33%|███▎      | 250/753 [1:37:05<2:59:52, 21.46s/it] 33%|███▎      | 251/753 [1:37:26<2:57:59, 21.27s/it]                                                     {'loss': 0.824, 'learning_rate': 1.165e-05, 'epoch': 0.33}
 33%|███▎      | 251/753 [1:37:26<2:57:59, 21.27s/it] 33%|███▎      | 252/753 [1:37:47<2:58:32, 21.38s/it]                                                     {'loss': 0.7448, 'learning_rate': 1.1700000000000001e-05, 'epoch': 0.33}
 33%|███▎      | 252/753 [1:37:47<2:58:32, 21.38s/it] 34%|███▎      | 253/753 [1:38:09<2:57:54, 21.35s/it]                                                     {'loss': 0.7657, 'learning_rate': 1.1750000000000001e-05, 'epoch': 0.34}
 34%|███▎      | 253/753 [1:38:09<2:57:54, 21.35s/it] 34%|███▎      | 254/753 [1:38:30<2:57:31, 21.35s/it]                                                     {'loss': 0.7548, 'learning_rate': 1.1799999999999999e-05, 'epoch': 0.34}
 34%|███▎      | 254/753 [1:38:30<2:57:31, 21.35s/it] 34%|███▍      | 255/753 [1:38:51<2:57:10, 21.35s/it]                                                     {'loss': 0.7551, 'learning_rate': 1.185e-05, 'epoch': 0.34}
 34%|███▍      | 255/753 [1:38:51<2:57:10, 21.35s/it] 34%|███▍      | 256/753 [1:39:13<2:56:13, 21.27s/it]                                                     {'loss': 0.7881, 'learning_rate': 1.19e-05, 'epoch': 0.34}
 34%|███▍      | 256/753 [1:39:13<2:56:13, 21.27s/it][2023-07-21 20:17:21,311] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 76104
[2023-07-21 20:17:21,311] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 76105
[2023-07-21 20:17:22,142] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 76106
[2023-07-21 20:17:23,010] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 76107
[2023-07-21 20:17:23,880] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 76108
[2023-07-21 20:17:24,710] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 76109
[2023-07-21 20:17:25,579] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 76110
[2023-07-21 20:17:26,409] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 76111
[2023-07-21 20:17:27,652] [ERROR] [launch.py:434:sigkill_handler] ['/root/anaconda3/envs/unichat/bin/python3.10', '-u', 'train.py', '--local_rank=7', '--model_name_or_path', '/data/caihua/huggingfaceModels/llama/llama-13B', '--model_max_length', '1024', '--data_path', '/data/renma/unigpt//law_data/wenshu5w/民事案件data', '--output_dir', '/data/renma/unigpt//KnowLM/pretrain/output', '--num_train_epochs', '1', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '1', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '100', '--save_total_limit', '1', '--learning_rate', '1.5e-5', '--warmup_steps', '300', '--logging_steps', '1', '--report_to', 'tensorboard', '--gradient_checkpointing', 'True', '--deepspeed', '/data/renma/unigpt//KnowLM/pretrain/configs/config.json', '--fp16', 'True', '--log_on_each_node', 'False', '--lr_scheduler_type', 'cosine', '--adam_beta1', '0.9', '--adam_beta2', '0.95', '--weight_decay', '0.1'] exits with return code = -9
